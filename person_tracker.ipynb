{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"YOLOv4_DeepSort.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"code","metadata":{"id":"pYywSkTvvuCN","executionInfo":{"status":"ok","timestamp":1605375975998,"user_tz":300,"elapsed":23221,"user":{"displayName":"Harold Giovanny García Rodríguez","photoUrl":"","userId":"18024655919742004881"}},"outputId":"36d642a8-e96a-48b8-8db9-4a2bd0c49030","colab":{"base_uri":"https://localhost:8080/"}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"source":["## Cloning the repository"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# clone repository\n","!git clone https://github.com/nestorsgarzonc/ds4a_computer_vision"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# step into the yolov4-deepsort folder\n","%cd ds4a_computer_vision/"]},{"source":["## Get YOLOv4 Pre-trained Weights\n","For this tutorial we will be using the pre-trained YOLOv4 model, trained on over 80 classes."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# download yolov4 model weights to data folder\n","!wget https://github.com/AlexeyAB/darknet/releases/download/darknet_yolo_v3_optimal/yolov4.weights -P data/"]},{"source":["## Convert YOLOv4 Darknet Weights to TensorFlow model\n","We will be running the DeepSort object tracker using TensorFlow. In order to accomplish this we must first convert the yolov4 weights into a tensorflow model."],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Convert darknet weights to tensorflow model\n","!python save_model.py --model yolov4"]},{"source":["## Running the Code"],"cell_type":"markdown","metadata":{}},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Run the person_tracker.py file indicating the path where the videos are located\n","!python person_tracker.py --videos_repository_path '/content/drive/My Drive/Data Vision Artificial/San Diego/Videos'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# We have the following flags to execute the person_tracker.py file\n","# --output_vid: path to output video (remember to set right codec for given format. e.g. XVID for .avi)\n","# (default: None)\n","# --output_format: codec used in VideoWriter when saving video to file\n","# (default: 'XVID')\n","# --weights_path: path to weights file\n","# (default: './checkpoints/yolov4-416')\n","# --size: resize images to\n","# (default: 416)\n","# --iou: iou threshold\n","# (default: 0.45)\n","# --score_th: confidence threshold\n","# (default: 0.50)\n","# --info: print detailed info about tracked objects\n","# (default: False)\n","# --display_count: count objects being tracked on screen\n","# (default: False)\n","# --output_csv_path: path to output detections csv file\n","# (default: './outputs/video_data.csv')\n","# --count_csv_path: path to output count csv file\n","# (default: './outputs/count_data.csv')\n","# --videos_repository_path: path to the stored videos\n","# (default: '/content/drive/My Drive/Data Vision Artificial/San Diego/Videos')"]}]}